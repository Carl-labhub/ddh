---
title: "Entrez summary"
output: html_notebook
---

##Load libraries & clear environment
```{r}
library(tidyverse)
library(lubridate)
library(rvest)
library(janitor)
library(feather)
library(here)
library(beepr)
library(vroom)

rm(list=ls()) #clear environment

#how long?
start_time <- Sys.time()
```

#downlaod entrez gene ids from hugo
```{r}
#from https://www.genenames.org/cgi-bin/download/custom?col=gd_hgnc_id&col=gd_app_sym&col=gd_app_name&col=gd_prev_sym&col=gd_aliases&col=gd_pub_chrom_map&col=gd_pub_refseq_ids&col=md_eg_id&col=gd_locus_type&col=md_mim_id&col=md_prot_id&status=Approved&hgnc_dbtag=on&order_by=gd_app_sym_sort&format=text&submit=submit

hugo <- vroom(here::here("data", "hugo.txt"), delim = "\t", col_names = TRUE) %>% 
  clean_names()
```

#scrape data
Using: https://github.com/tidyverse/rvest
From: https://www.ncbi.nlm.nih.gov/gene/

```{r scrape, eval=FALSE}
entrez <- tibble(
  i = numeric(), 
  entrez_symbol = character(), 
  entrez_category = character(),
  entrez_summary = character()
)

ids <- hugo %>% 
  drop_na(ncbi_gene_id_supplied_by_ncbi) %>% 
  sample_n(10) %>% 
  pull(ncbi_gene_id_supplied_by_ncbi)
  
for (i in ids) {
  message("Getting entry ", i)
  Sys.sleep(5) #add sleepy time according to https://www.ncbi.nlm.nih.gov/robots.txt
  url <- read_html(paste0("https://www.ncbi.nlm.nih.gov/gene/", i))
  
  entrez_symbol <- url %>% 
    html_nodes("dd.noline") %>% #got from inspect element
    html_text() %>% 
    str_remove("provided\\sby\\sHGNC")
  
  entrez_category <- url %>% 
    html_nodes("dt:nth-child(19)") %>% #got from inspect element
    html_text()
  
  entrez_summary <- url %>% 
    html_nodes("dd:nth-child(20)") %>% #got from inspect element
    html_text()
  
  tmp <- tibble(i, entrez_symbol, entrez_category, entrez_summary)

  entrez <- entrez %>% 
    bind_rows(tmp)
}

entrez <- entrez %>% 
  filter(entrez_category == "Summary")

#The rvest code scrapes by position in the <div>, but depenidng on which information is available, the summary position might provide other information. So I get all the summary, as well as the junk, and then filter out the junk with the last line of code

beep(sound = 8) #because mario is awesome

#how long to scrape?
end_time <- Sys.time()
time_taken <- round(as.duration(start_time %--% end_time)/dminutes(1), digits = 1)
print(time_taken) #4days

#save
write_feather(entrez, path = here::here("entrez.feather"))
write_csv(entrez, path = here::here("entrez.csv"))
```


```{r reimport}
entrez <- vroom(here::here("data", "entrez.csv"), delim = ",", col_names = TRUE) %>% 
  rename(ncbi_gene_id_supplied_by_ncbi = i) %>% 
  filter(entrez_category == "Summary") %>% 
  select(-entrez_category, -entrez_symbol)

#join and clean
gene_summary <- hugo %>% 
  left_join(entrez) %>% 
  rename(ncbi_gene_id = ncbi_gene_id_supplied_by_ncbi)

gene_summary$entrez_summary <- replace_na(gene_summary$entrez_summary, "No NCBI summary")
gene_summary$locus_type <- str_to_sentence(gene_summary$locus_type)
gene_summary$locus_type <- str_replace(gene_summary$locus_type, "Rna", "RNA")
gene_summary$approved_name <- str_to_sentence(gene_summary$approved_name)

gene_summary <- gene_summary %>% 
  unite("aka", previous_symbols:synonyms, sep = ", ", na.rm = TRUE)
```


```{r output}
write_feather(gene_summary, path = here::here("data", "gene_summary.feather"))

#test input
#gene_summary <- read_feather(path = here::here("data", "gene_summary.feather"))

```

#print Session information for provenance and reproducibility
```{r session_info}
utils:::print.sessionInfo(sessionInfo()[-8]) 
#You can remove an item from sessionInfo(), which is a list with a class attribute, by printing the resulting object omitting one of the list items (omitted list of packages installed, but not loaded)
```
